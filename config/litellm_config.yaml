# =============================================================================
# LiteLLM Configuration - System B+R
# =============================================================================

model_list:
  # =============================================================================
  # Production Models (require API keys)
  # =============================================================================
  
  # OpenAI GPT-4o - Best for document classification
  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 4096
      temperature: 0.1
    model_info:
      description: "OpenAI GPT-4o for document analysis and classification"
      
  - model_name: gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 4096
      temperature: 0.1
    model_info:
      description: "OpenAI GPT-4o-mini for fast classification"

  # Anthropic Claude - Best for reasoning
  - model_name: claude-sonnet
    litellm_params:
      model: anthropic/claude-sonnet-4-20250514
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 4096
      temperature: 0.1
    model_info:
      description: "Anthropic Claude Sonnet for complex reasoning"

  # =============================================================================
  # OpenRouter Models (remote LLM via OpenRouter.ai)
  # =============================================================================
  
  # OpenRouter dynamic model - only works when OPENROUTER_MODEL is set
  # Commented out to avoid startup errors when env var is empty
  # - model_name: openrouter
  #   litellm_params:
  #     model: os.environ/OPENROUTER_MODEL
  #     api_key: os.environ/OPENROUTER_API_KEY
  #     api_base: https://openrouter.ai/api/v1
  #     max_tokens: 4096
  #     temperature: 0.1
  #   model_info:
  #     description: "OpenRouter model - configurable via OPENROUTER_MODEL env var"

  - model_name: openrouter-claude
    litellm_params:
      model: openrouter/anthropic/claude-3.5-sonnet
      api_key: os.environ/OPENROUTER_API_KEY
      max_tokens: 4096
      temperature: 0.1
    model_info:
      description: "Claude 3.5 Sonnet via OpenRouter"

  - model_name: openrouter-gpt4
    litellm_params:
      model: openrouter/openai/gpt-4-turbo
      api_key: os.environ/OPENROUTER_API_KEY
      max_tokens: 4096
      temperature: 0.1
    model_info:
      description: "GPT-4 Turbo via OpenRouter"

  # =============================================================================
  # Local Models via Ollama (no API key needed)
  # =============================================================================
  
  # Llama 3.2 - Good for Polish text
  - model_name: llama3.2
    litellm_params:
      model: ollama/llama3.2
      api_base: os.environ/OLLAMA_API_BASE
      max_tokens: 4096
      temperature: 0.1
    model_info:
      description: "Llama 3.2 via Ollama for local processing"

  # Mistral - Fast local model
  - model_name: mistral
    litellm_params:
      model: ollama/mistral
      api_base: os.environ/OLLAMA_API_BASE
      max_tokens: 4096
      temperature: 0.1
    model_info:
      description: "Mistral via Ollama for fast local processing"

  # Qwen 2.5 - Good multilingual support
  - model_name: qwen2.5
    litellm_params:
      model: ollama/qwen2.5
      api_base: os.environ/OLLAMA_API_BASE
      max_tokens: 4096
      temperature: 0.1
    model_info:
      description: "Qwen 2.5 via Ollama with good Polish support"

  # =============================================================================
  # Router Models (with fallbacks)
  # =============================================================================
  
  # Document Classifier - tries production first, falls back to local
  - model_name: br-classifier
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 2048
      temperature: 0
    model_info:
      description: "Primary B+R document classifier"

  - model_name: br-classifier-fallback
    litellm_params:
      model: ollama/llama3.2
      api_base: os.environ/OLLAMA_API_BASE
      max_tokens: 2048
      temperature: 0
    model_info:
      description: "Fallback B+R classifier (local)"

  # Report Generator
  - model_name: br-report-generator
    litellm_params:
      model: anthropic/claude-sonnet-4-20250514
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 8192
      temperature: 0.3
    model_info:
      description: "B+R report generator for US documentation"

# =============================================================================
# Router Settings
# =============================================================================
router_settings:
  routing_strategy: simple-shuffle
  num_retries: 3
  timeout: 120
  
  # Fallback configuration
  fallbacks:
    - br-classifier: [br-classifier-fallback, openrouter-claude]
    - gpt-4o: [claude-sonnet, openrouter-claude, llama3.2]
    - claude-sonnet: [gpt-4o, openrouter-gpt4, llama3.2]
    - openrouter-claude: [openrouter-gpt4, llama3.2]

  # Model group aliases
  model_group_alias:
    classifier: [br-classifier, br-classifier-fallback]
    generator: [br-report-generator, gpt-4o]
    fast: [gpt-4o-mini, mistral]

# =============================================================================
# Litellm Settings
# =============================================================================
litellm_settings:
  # Caching
  cache: True
  cache_params:
    type: redis
    host: redis
    port: 6379
    
  # Logging (disabled - langfuse not installed)
  # success_callback: ["langfuse"]
  # failure_callback: ["langfuse"]
  
  # Rate limiting
  max_budget: 100  # USD per month
  budget_duration: 1mo

  # Request settings
  request_timeout: 120
  set_verbose: false
  json_logs: true

# =============================================================================
# General Settings
# =============================================================================
general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY
  
  # Database for spend tracking
  database_url: os.environ/DATABASE_URL
  
  # Alerting
  alerting:
    - slack
  alerting_threshold: 50  # Alert when budget reaches 50%
